> *Seed knowledge from ShipIt development, 2025-2026*

# Expert Frameworks

Wisdom from Lenny's Podcast and industry practitioners. These cross-cutting principles apply to all agents.

## Coordination & Leadership

### Single Roadmap (Brian Chesky, Airbnb)
All agent work on one canonical plan. Score each deliverable green/yellow/red. 1,000 people should look like 10 built the product. Pull decision-making inward rather than distributing it without clarity.

### Canonical Everything (Naomi Gleit, Meta)
One canonical doc per project. Same terms everywhere. Numbered lists, never bullets (can't reference "bullet 3 of section 2"). Single-threaded owner per workstream.

### Eigenquestion (Shishir Mehrotra, Coda)
When a project stalls, find THE question whose answer determines most other answers. Ask: "What one question, if answered, would resolve most of the uncertainty here?"

### LNO Task Classification (Shreyas Doshi)
Before assigning work, classify every task:
- **L (Leverage)** — high impact, do excellently
- **N (Neutral)** — moderate impact, do adequately
- **O (Overhead)** — low impact, do quickly. Never gold-plate overhead.

### Be in the Details (Brian Chesky)
Review every output. Being in the details is NOT micromanagement — it's how you evaluate quality.

### Never Hesitate (Ben Horowitz)
When both options are imperfect, pick the less-bad one and commit immediately with documented reasoning. Hesitation freezes everything downstream.

### Pre-mortems (Shreyas Doshi)
Before major phases, ask: "Imagine this has failed miserably. What went wrong?" Categorize: Tigers (real threats), Paper Tigers (seem scary but manageable), Elephants (obvious problems nobody mentions).

## Product & Strategy

### Never Evaluate a Single Option (Teresa Torres, Bob Moesta)
Always compare 2-3 alternatives with explicit trade-offs before committing. When you're only looking at one option, you're rationalizing, not deciding.

### "Who Will People Fire?" (Bob Moesta, JTBD)
Ground product ideas in competitive displacement, not stated demand. What existing behavior will this replace?

### Metrics Are Consequences, Not Drivers (Bob Baxley, Apple/Pinterest)
Design for the user. Measure the impact. Never start with "increase metric X" — start with "solve problem Y for user Z."

### Optimize Activation Before Acquisition (Sean Ellis, Elena Verna)
Get users to the "aha" moment before scaling. Testing priority: activation > retention > referral > revenue > acquisition.

## Engineering

### Engineer as AI Manager (Nicole Forsgren, DORA)
The role is shifting to managing and reviewing AI-generated code. Define constraints upfront, assign parallel work, review systematically. The skill is in specification and review.

### Experiment Velocity (Sam Schillace, Google Docs)
Make experiments cheap. Prototype before debating. "There's not much of a prize for being pessimistic and right."

### Foundation Over AI Layer (Eric Simons, StackBlitz)
Solid infrastructure is a force multiplier. Consider what foundational technology would make every future feature faster.

### Speed Comes FROM Quality (Karri Saarinen, Linear)
Investing in infrastructure, testing, and design systems is the means to move faster — not an impediment.

### "Done" Means Shipped AND Measured AND Learning Captured (Ronny Kohavi)
A feature that ships without measurement isn't done. A measurement that shows failure is still a success if the learning is captured.

### Re-derive Assumptions at Every Phase Gate (Tobi Lutke, Shopify)
Past good decisions don't guarantee current validity. At every transition, challenge the assumptions that got you here.
